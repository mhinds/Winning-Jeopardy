{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "This notebook explores a dataset containing ~200,000 questions from 1984 - 2012. It explores various strategies for gaining an advantage into the quesiton answer. \n",
    "\n",
    "First import the data and examine the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jeopardy = pd.read_csv('JEOPARDY_CSV.csv')\n",
    "print(jeopardy.head())\n",
    "jeopardy = jeopardy.rename(index=str, columns={' Air Date':'Air Date', ' Question': 'Question', ' Round':'Round', ' Category':'Category', ' Value':'Value', ' Answer':'Answer'})\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few interesting things come to mind to explore:\n",
    "\n",
    "### 1. Is it possible to glean the answer from reading the question?\n",
    "### 2. Is studying old questions a good strategy for preparation?\n",
    "### 3. Can studying be focused on high value question material?\n",
    "\n",
    "Before analyzing the questions and answers they should be cleaned, tokenized, \n",
    "and stemmed. The following functions remove punctuation, tokenize the text, filter out\n",
    "stop words, and stem the remaining words. NLTK is used for some of the text functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk import ngrams\n",
    "\n",
    "trans = {}\n",
    "for c in string.punctuation:\n",
    "    trans[c] = ''\n",
    "table = str.maketrans(trans)\n",
    "\n",
    "def normalize_text(s):\n",
    "    return s.lower().translate(table)\n",
    "\n",
    "def clean_values(s):\n",
    "    v = s.translate(table)\n",
    "    try:\n",
    "        return int(v)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def remove_stopwords(word_list):\n",
    "    return [word for word in word_list if word not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [PorterStemmer().stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(remove_stopwords(tokens))\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(clean_values)\n",
    "jeopardy['clean_air_date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Is it possible to glean the answer from reading the question?\n",
    "When competing on the show how feasible is it to gain the answer from the\n",
    "question? This can be determined by first cleaning each question and answer\n",
    "so that we are only dealing with important stemmed words. Then, count how \n",
    "many terms from the answer also appear in the question. By dividing by the total \n",
    "number of words in the answer a metric can be established. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_question_answer_similarities(row):\n",
    "    q = tokenize(row['clean_question'])\n",
    "    a = tokenize(row['clean_answer'])\n",
    "    match_count = 0\n",
    "    if len(q) == 0 or len(a) == 0:\n",
    "        return 0\n",
    "    for term in a:\n",
    "        if term in q:\n",
    "            match_count +=1\n",
    "    return match_count/len(a)\n",
    "\n",
    "jeopardy['qa_similarity'] = jeopardy.apply(get_question_answer_similarities,axis=1)\n",
    "mean = jeopardy['qa_similarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Q/A Similarity: 0.04163852739914068\n",
      "Q: if he shows off a person from frankfurt is a hot dog but either way hes one of these\n",
      "A: frankfurter\n",
      "S: 1.0\n",
      "Q: salt pepper sage\n",
      "A: sage\n",
      "S: 1.0\n",
      "Q: of an artist a fish or a wasp its what a mud dauber is\n",
      "A: wasp\n",
      "S: 1.0\n",
      "Q: wind wander wonderful\n",
      "A: wonderful\n",
      "S: 1.0\n",
      "Q: of bruising blanching or browning the one that involves boiling water\n",
      "A: blanching\n",
      "S: 1.0\n",
      "Q: of the atlantic pacific or the arctic the ocean that blue point oysters come from\n",
      "A: the atlantic\n",
      "S: 1.0\n",
      "Q: town in sd that put up 9 statue of fr pierre jean de smet who died in 1873  never visited the town\n",
      "A: de smet\n",
      "S: 1.0\n",
      "Q: of a future land a patent medicine or an alien visitor what hg wells tonobungay is\n",
      "A: patent medicine\n",
      "S: 1.0\n",
      "Q: koi bolshoi borzoi bok choy\n",
      "A: a borzoi\n",
      "S: 1.0\n",
      "Q: invented in the late 50s its a functional circuit formed when diodes transistors etc are integrated\n",
      "A: integrated circuit\n",
      "S: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhinds/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#Just printing stuff here\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "print(\"Average Q/A Similarity:\",mean)\n",
    "jeopardy = jeopardy.sort('qa_similarity',ascending=False)\n",
    "for i in range(10):\n",
    "    q = str(jeopardy['clean_question'].iloc[i])\n",
    "    a = str(jeopardy['clean_answer'].iloc[i])\n",
    "    s = str(jeopardy['qa_similarity'].iloc[i])\n",
    "    print_full('Q: '+q+'\\nA: '+a+\"\\nS: \"+s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average similarity between question and answer is ~4% indicating that the vast majority\n",
    "questions do not contain the answers. Perhaps this is not a good strategy for winning at \n",
    "Jeopardy. \n",
    "\n",
    "Even looking at the questions and answers that were ranked most similar, it seems a difficult\n",
    "task to glean the answer from the question. In nearly all cases where the answer is 100% \n",
    "contained in the question, the question is intended to contain the answer in the form of a scramble or a \"pick the one that doesn't belong\".\n",
    "\n",
    "### 2. Is studying old questions a good strategy for preparation?\n",
    "\n",
    "Try an n-gram analysis on the cleaned questions. Do newer questions reuse n-grams from older questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhinds/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEZCAYAAAB1mUk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCDJICIiSDKIiAiSDCIigiSDiIgA/j/iKpQLbiWvRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1208a9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def n_grams(string, n):\n",
    "    tokens = tokenize(string)\n",
    "    return ngrams(tokens,n)\n",
    "\n",
    "jeopardy = jeopardy.sort('clean_air_date')\n",
    "\n",
    "nlist = [1,2,3,4,5,6] ##set check the list of ngrams\n",
    "terms_list = []\n",
    "#print(nlist)\n",
    "averages = []\n",
    "for n in nlist:    \n",
    "    terms_used = set()\n",
    "    question_overlap = []\n",
    "    for i,row in jeopardy.iterrows():\n",
    "        q = list(n_grams(row['clean_question'],n))\n",
    "        #print(list(q))\n",
    "        match_count = 0\n",
    "        if len(q) > 0:\n",
    "            for term in q:   \n",
    "                if term in terms_used:\n",
    "                    match_count+=1\n",
    "            for term in q:\n",
    "                terms_used.add(term)\n",
    "            question_overlap.append(match_count/len(q))\n",
    "        else:\n",
    "            question_overlap.append(0)\n",
    "    jeopardy['question_overlap'] = question_overlap\n",
    "    #print(jeopardy['question_overlap'].mean())\n",
    "    averages.append(jeopardy['question_overlap'].mean())\n",
    "    terms_list.append(terms_used)\n",
    "    #print(averages)\n",
    "plt.bar(left=nlist,height=averages,align='center')\n",
    "plt.title(\"NGram Question Overlap\")\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"Average Question Overlap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question overlap of newer questions with older ones falls off rapidly as the size of the ngram increases. Although limited in its usefulness, this analysis indicates that not much is reused from previous questions. Another interesting approach might be to augment the current analysis using NLTK wordnet to better match meaning in the ngrams. This may be too time consuming given the size of the dataset. \n",
    "\n",
    "### 3. Can studying be focused on high value question material?\n",
    "\n",
    "First, high value and low value questions should be identified. Then, a chisquare test can be used to determine if any of the keywords are statistical outliers. Since a chisquare test requires at least 5 samples to be valid, words with less frequency should be thrown out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poem': (340, 540), 'nightingal': (8, 12), 'schoolboy': (3, 11), 'greatli': (7, 17), 'muniz': (2, 9), 'kuwait': (7, 12), 'newsmagazin': (2, 14), 'tuskege': (3, 15), '110': (13, 28), 'sterl': (6, 19)}\n"
     ]
    }
   ],
   "source": [
    "def is_high_value(row):\n",
    "    if row['clean_value'] > 800:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "def get_word_value_counts(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i,row in jeopardy.iterrows():\n",
    "        if word in tokenize(row['clean_question']):\n",
    "            if row['high_value'] == 1:\n",
    "                high_count +=1\n",
    "            else:\n",
    "                low_count +=1\n",
    "    return high_count,low_count\n",
    "\n",
    "observed_expected={}\n",
    "comparison_terms = [list(terms_list[0])[i][0] for i in range(50)]\n",
    "\n",
    "jeopardy['high_value']=jeopardy.apply(is_high_value,axis=1)\n",
    "for term in comparison_terms:\n",
    "    vc = get_word_value_counts(term)\n",
    "    if vc[0] > 5 or vc[1] > 5:\n",
    "        observed_expected[term]=vc\n",
    "print(observed_expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poem [340 540] [ 249.1649841  630.8350159]\n",
      "nightingal [ 8 12] [  5.66284055  14.33715945]\n",
      "schoolboy [ 3 11] [  3.96398838  10.03601162]\n",
      "greatli [ 7 17] [  6.79540866  17.20459134]\n",
      "muniz [2 9] [ 3.1145623  7.8854377]\n",
      "kuwait [ 7 12] [  5.37969852  13.62030148]\n",
      "newsmagazin [ 2 14] [  4.53027244  11.46972756]\n",
      "tuskege [ 3 15] [  5.09655649  12.90344351]\n",
      "110 [13 28] [ 11.60882312  29.39117688]\n",
      "sterl [ 6 19] [  7.07855068  17.92144932]\n",
      "('poem', Power_divergenceResult(statistic=46.194095079174488, pvalue=1.0709927725371787e-11))\n",
      "('nightingal', Power_divergenceResult(statistic=1.3455791016283176, pvalue=0.24605247364517135))\n",
      "('schoolboy', Power_divergenceResult(statistic=0.32702285677427062, pvalue=0.56741741894668074))\n",
      "('greatli', Power_divergenceResult(statistic=0.0085926239747985671, pvalue=0.92614475107497785))\n",
      "('muniz', Power_divergenceResult(statistic=0.55638902743969942, pvalue=0.45571882813430864))\n",
      "('kuwait', Power_divergenceResult(statistic=0.68077029797680078, pvalue=0.40932160095287651))\n",
      "('newsmagazin', Power_divergenceResult(statistic=1.9714107930420057, pvalue=0.16029819384346422))\n",
      "('tuskege', Power_divergenceResult(statistic=1.2031040152837962, pvalue=0.27270216713336393))\n",
      "('110', Power_divergenceResult(statistic=0.23256448143807618, pvalue=0.62962878955327217))\n",
      "('sterl', Power_divergenceResult(statistic=0.22924699514627792, pvalue=0.63208273316191876))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "high_value_count = len(jeopardy[jeopardy['high_value']==1])\n",
    "low_value_count = len(jeopardy[jeopardy['high_value']==0])\n",
    "chi_squared = []\n",
    "for term in observed_expected:\n",
    "    total = observed_expected[term][0]+observed_expected[term][1]\n",
    "    total_prop = total/len(jeopardy)\n",
    "    expected_val_high = total_prop*high_value_count\n",
    "    expected_val_low = total_prop*low_value_count\n",
    "    observed = np.array([observed_expected[term][0],observed_expected[term][1]])\n",
    "    expected = np.array([expected_val_high, expected_val_low])\n",
    "    print(term,observed,expected)\n",
    "    chi_squared.append(chisquare(observed,expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting term frequency takes a while due to the size of the dataset (this could probably be improved by caching the term frequencies from number 2), so the scope is limited to the first 50 or so terms. Of those, most are thrown out due to infrequency. One term, \"poem\", does stand out as being particularly frequent and having a high likelihood of being used in high-value questions. If you are studying to compete on Jeopardy, then you would do well to spend extra time studying poems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
